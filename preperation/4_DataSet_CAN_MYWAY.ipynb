{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat after Normalization\n",
    "\n",
    "### recommended!\n",
    "\n",
    "- 이렇게 해야지만 feature가 누락되지 않고 데이터가 살아있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "from natsort import natsorted\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler ,RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from os.path import join\n",
    "\n",
    "from pickle import dump, load\n",
    "\n",
    "seed_rand = 777 # 2nd 777 # 1st 41\n",
    "nameDataset = \"IWALQQ_2nd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeColumnsWOMAG():\n",
    "    SIDEIDX = ['non','oa']\n",
    "    PARTIDX = ['shank','shoe','thigh']\n",
    "    TYPEIDX = ['ACC','GYRO','MAG']\n",
    "    AXISIDX = ['X', 'Y', 'Z']\n",
    "    LEGCOLUMNSLENGTH = 54\n",
    "    COl_imu_legs = [f'{SIDEIDX[int(i//(LEGCOLUMNSLENGTH/2))]}\\\n",
    "_{PARTIDX[(i//(len(TYPEIDX)*len(AXISIDX)))%len(PARTIDX)]}\\\n",
    "_{TYPEIDX[(i//(len(AXISIDX)))%len(TYPEIDX)]}\\\n",
    "_{AXISIDX[i%len(AXISIDX)]}' for i in range(0,LEGCOLUMNSLENGTH)]\n",
    "    TRKCOLUMNSLENGTH = 9\n",
    "    Col_imu_trunk = [f'trunk_{TYPEIDX[(i//(len(AXISIDX)))%len(TYPEIDX)]}_{AXISIDX[i%len(AXISIDX)]}' for i in range(0,TRKCOLUMNSLENGTH)]\n",
    "    # Columns for forceplate\n",
    "    FPCOLUMNSLENGTH = 12\n",
    "    FPTYPEIDX = ['GRF','ANGLE','MONM','MOBWHT']\n",
    "    Col_FP = [f'{FPTYPEIDX[(i//(len(AXISIDX)))%len(FPTYPEIDX)]}_{AXISIDX[i%len(AXISIDX)]}' for i in range(0,FPCOLUMNSLENGTH)]\n",
    "    # 최종 column\n",
    "    newColumns = COl_imu_legs+Col_imu_trunk+Col_FP\n",
    "    newColumnswithoutMAG = [col for col in newColumns if not 'MAG' in col] \n",
    "    return newColumnswithoutMAG\n",
    "\n",
    "# subject로 분류한 것을 다시 전체 데이터 index 기준으로 변경하기\n",
    "# subject로 Kfold로 된것을 subject fold로 바꿔주는 함수\n",
    "def kfold2subfold(arrName,listData,train,test):\n",
    "    arrTrain = []\n",
    "    arrTest = []\n",
    "    for pID in arrName[train]:\n",
    "        idxofID = listData.index[listData['patientID']==pID].copy()\n",
    "        arrTrain.extend(idxofID.to_list())\n",
    "\n",
    "    for pID in arrName[test]:\n",
    "        idxofID = listData.index[listData['patientID']==pID].copy()\n",
    "        arrTest.extend(idxofID.to_list())\n",
    "    return arrTrain, arrTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "항상 listfileName의 수와 dataList는 순서와 개수가 일치해야한다\n",
      "\n",
      "Num_listFromxlsx: 877 | Num_listFromFolder: 877\n",
      "Is same size: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  patientID  dateVisit speed  numtrial    side  numStep\n",
       " 0      P002      31220     w         7  nonleg        1\n",
       " 1      P002      31220     w         7  nonleg        2\n",
       " 2      P002      31220     w         7   oaleg        1\n",
       " 3      P002      31220     w         8  nonleg        1\n",
       " 4      P002      31220     w         8   oaleg        1,\n",
       " ['N_F_P002_031220_w_0007_nonleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0007_nonleg_imu_knee_angle_moment_2_Step.csv',\n",
       "  'N_F_P002_031220_w_0007_oaleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0008_nonleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0008_oaleg_imu_knee_angle_moment_1_Step.csv'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 dir 설정\n",
    "dataDir =     r'Z:\\PROJECTS\\iwalqq\\Data\\V3D\\Output\\IMU Deep Learning\\Data\\20220325_raw_byDeepak_csv\\INC_ByStep\\INC_ByZero\\Included_checked'\n",
    "normalizedDir = join(dataDir, r'NORM')\n",
    "#######################################################\n",
    "# 설정창\n",
    "# 이번에는 time-normalized 한 data를 씀 무슨 데이터 길이든 101로 만든 것\n",
    "TargetDir = normalizedDir\n",
    "#######################################################\n",
    "# 파일목록 가져오기\n",
    "# 파일 목록 전체 들고오고 필요한 확장자만 고르고 들고온 파일 목록에서 .txt만 남기고 나머지 것들 제외시키기\n",
    "dataExt = r\".csv\"\n",
    "listFromFolder = natsorted([_ for _ in os.listdir(TargetDir) if _.endswith(dataExt)])\n",
    "# 파일 정리한 목록 불러오기\n",
    "listfileName  = r'list_dataset.xlsx'\n",
    "listFromxlsx = pd.read_excel(join(dataDir,listfileName))\n",
    "#인원 추출하기\n",
    "arrName = listFromxlsx.patientID.unique()\n",
    "print(\"항상 listfileName의 수와 dataList는 순서와 개수가 일치해야한다\")\n",
    "print(f\"\\nNum_listFromxlsx: {len(listFromxlsx)} | Num_listFromFolder: {len(listFromFolder)}\")\n",
    "print(f'Is same size: {len(listFromxlsx)==len(listFromFolder)}')\n",
    "listFromxlsx.head(), listFromFolder[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "항상 listfileName의 수와 dataList는 순서와 개수가 일치해야한다\n",
      "\n",
      "Num_listFromxlsx: 877 | Num_listFromFolder: 877\n",
      "Is same size: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  patientID  dateVisit speed  numtrial    side  numStep\n",
       " 0      P002      31220     w         7  nonleg        1\n",
       " 1      P002      31220     w         7  nonleg        2\n",
       " 2      P002      31220     w         7   oaleg        1\n",
       " 3      P002      31220     w         8  nonleg        1\n",
       " 4      P002      31220     w         8   oaleg        1,\n",
       " ['N_F_P002_031220_w_0007_nonleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0007_nonleg_imu_knee_angle_moment_2_Step.csv',\n",
       "  'N_F_P002_031220_w_0007_oaleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0008_nonleg_imu_knee_angle_moment_1_Step.csv',\n",
       "  'N_F_P002_031220_w_0008_oaleg_imu_knee_angle_moment_1_Step.csv'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 dir 설정\n",
    "dataDir =     r'.'\n",
    "normalizedDir = join(dataDir, r'NORM')\n",
    "#######################################################\n",
    "# 설정창\n",
    "# 이번에는 time-normalized 한 data를 씀 무슨 데이터 길이든 101로 만든 것\n",
    "TargetDir = normalizedDir\n",
    "#######################################################\n",
    "# 파일목록 가져오기\n",
    "# 파일 목록 전체 들고오고 필요한 확장자만 고르고 들고온 파일 목록에서 .txt만 남기고 나머지 것들 제외시키기\n",
    "dataExt = r\".csv\"\n",
    "listFromFolder = natsorted([_ for _ in os.listdir(TargetDir) if _.endswith(dataExt)])\n",
    "# 파일 정리한 목록 불러오기\n",
    "listfileName  = r'list_dataset.xlsx'\n",
    "listFromxlsx = pd.read_excel(join(dataDir,listfileName))\n",
    "#인원 추출하기\n",
    "arrName = listFromxlsx.patientID.unique()\n",
    "print(\"항상 listfileName의 수와 dataList는 순서와 개수가 일치해야한다\")\n",
    "print(f\"\\nNum_listFromxlsx: {len(listFromxlsx)} | Num_listFromFolder: {len(listFromFolder)}\")\n",
    "print(f'Is same size: {len(listFromxlsx)==len(listFromFolder)}')\n",
    "listFromxlsx.head(), listFromFolder[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 만들기\n",
    "- 모든 것보다 데이터 split이 가장 먼저 선행되어야 함!\n",
    "- 데이터 셋을 train|valid|test(80|10|10)으로 나누기 보다 5-fold cross-validation을 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 함수 및 class 설정\n",
    "def make_dir(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "        \n",
    "# (N , M , P) shape을 가진 입력 데이터를 scaling 할 때 사용!\n",
    "# 아래 함수는 전체 데이터 셋에 column-wise로 적용됨!\n",
    "# 짱 편함..\n",
    "class MinMaxScaler3D(MinMaxScaler):\n",
    "    # def fit_transform(self, X, y=None):\n",
    "    #     x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "    #     return np.reshape(super().fit_transform(x, y=y), newshape=X.shape)\n",
    "    def fit(self, X, y=None):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        super().fit(x, y=y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().transform(x), newshape=X.shape)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().inverse_transform(x), newshape=X.shape)\n",
    "\n",
    "class StandardScaler3D(StandardScaler):\n",
    "    # def fit_transform(self, X, y=None):\n",
    "    #     x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "    #     return np.reshape(super().fit_transform(x, y=y), newshape=X.shape)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        super().fit(x, y=y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().transform(x), newshape=X.shape)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().inverse_transform(x), newshape=X.shape)\n",
    "\n",
    "class RobustScaler3D(RobustScaler):\n",
    "    # def fit_transform(self, X, y=None):\n",
    "    #     x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "    #     return np.reshape(super().fit_transform(x, y=y), newshape=X.shape)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        super().fit(x, y=y)\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().transform(x), newshape=X.shape)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().inverse_transform(x), newshape=X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 K-fold 용\n",
    "- 본 cell을 열어서 돌리면 K-fold로 된 K 쌍의 (train set,test set, fitted scaler) 이 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subject:44\n",
      "Total Data size:877\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "Num. of fold: 0\n",
      "\n",
      "['P002' 'P007' 'P017' 'P029' 'P050' 'P061' 'P065' 'P066' 'P069' 'P105'\n",
      " 'P115' 'P119' 'P121' 'P135' 'P136' 'P147' 'P149' 'P168' 'P169' 'P172'\n",
      " 'P203' 'P222' 'P225' 'P226' 'P229' 'P243' 'P258' 'P263' 'P266' 'P270'\n",
      " 'P272' 'P273' 'P277' 'P290' 'P297']\n",
      "Num for train:35\n",
      "\n",
      "['P104' 'P106' 'P132' 'P134' 'P142' 'P155' 'P196' 'P205' 'P245']\n",
      "Num for test:9\n",
      "\n",
      "Num total:44\n",
      "\n",
      "0_fold\n",
      "idx4train:702 | idx4test:175 | total:877/877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb5c33984aa4e8595c280521bf78716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  702\n",
      "Final shape: (702, 4242, 1), (702, 303, 1), (702, 303, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ac89a4e6b648be98e0f067855fc992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  175\n",
      "Final shape: (175, 4242, 1), (175, 303, 1), (175, 303, 1)\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "Num. of fold: 1\n",
      "\n",
      "['P007' 'P050' 'P061' 'P065' 'P066' 'P104' 'P105' 'P106' 'P119' 'P121'\n",
      " 'P132' 'P134' 'P136' 'P142' 'P147' 'P155' 'P168' 'P169' 'P172' 'P196'\n",
      " 'P203' 'P205' 'P222' 'P225' 'P226' 'P229' 'P243' 'P245' 'P258' 'P263'\n",
      " 'P270' 'P272' 'P273' 'P277' 'P290']\n",
      "Num for train:35\n",
      "\n",
      "['P002' 'P017' 'P029' 'P069' 'P115' 'P135' 'P149' 'P266' 'P297']\n",
      "Num for test:9\n",
      "\n",
      "Num total:44\n",
      "\n",
      "1_fold\n",
      "idx4train:678 | idx4test:199 | total:877/877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596c0345eb0b42e69828fd99d4cf9685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  678\n",
      "Final shape: (678, 4242, 1), (678, 303, 1), (678, 303, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ccfd63da9a4672bcc67dcf150264f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  199\n",
      "Final shape: (199, 4242, 1), (199, 303, 1), (199, 303, 1)\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "Num. of fold: 2\n",
      "\n",
      "['P002' 'P007' 'P017' 'P029' 'P061' 'P066' 'P069' 'P104' 'P106' 'P115'\n",
      " 'P119' 'P121' 'P132' 'P134' 'P135' 'P136' 'P142' 'P147' 'P149' 'P155'\n",
      " 'P168' 'P169' 'P172' 'P196' 'P203' 'P205' 'P222' 'P229' 'P245' 'P263'\n",
      " 'P266' 'P270' 'P272' 'P273' 'P297']\n",
      "Num for train:35\n",
      "\n",
      "['P050' 'P065' 'P105' 'P225' 'P226' 'P243' 'P258' 'P277' 'P290']\n",
      "Num for test:9\n",
      "\n",
      "Num total:44\n",
      "\n",
      "2_fold\n",
      "idx4train:688 | idx4test:189 | total:877/877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8564bae22548a9b484436d265319d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  688\n",
      "Final shape: (688, 4242, 1), (688, 303, 1), (688, 303, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d64c7be8fe14ca2902c9feb8cb2b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  189\n",
      "Final shape: (189, 4242, 1), (189, 303, 1), (189, 303, 1)\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "Num. of fold: 3\n",
      "\n",
      "['P002' 'P017' 'P029' 'P050' 'P065' 'P066' 'P069' 'P104' 'P105' 'P106'\n",
      " 'P115' 'P132' 'P134' 'P135' 'P136' 'P142' 'P149' 'P155' 'P168' 'P169'\n",
      " 'P172' 'P196' 'P205' 'P222' 'P225' 'P226' 'P243' 'P245' 'P258' 'P266'\n",
      " 'P270' 'P272' 'P277' 'P290' 'P297']\n",
      "Num for train:35\n",
      "\n",
      "['P007' 'P061' 'P119' 'P121' 'P147' 'P203' 'P229' 'P263' 'P273']\n",
      "Num for test:9\n",
      "\n",
      "Num total:44\n",
      "\n",
      "3_fold\n",
      "idx4train:694 | idx4test:183 | total:877/877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631843206d0748608ea43682d01e2dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/694 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  694\n",
      "Final shape: (694, 4242, 1), (694, 303, 1), (694, 303, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d04e6ab1583476ca280d5831154445b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  183\n",
      "Final shape: (183, 4242, 1), (183, 303, 1), (183, 303, 1)\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\n",
      "Num. of fold: 4\n",
      "\n",
      "['P002' 'P007' 'P017' 'P029' 'P050' 'P061' 'P065' 'P069' 'P104' 'P105'\n",
      " 'P106' 'P115' 'P119' 'P121' 'P132' 'P134' 'P135' 'P142' 'P147' 'P149'\n",
      " 'P155' 'P196' 'P203' 'P205' 'P225' 'P226' 'P229' 'P243' 'P245' 'P258'\n",
      " 'P263' 'P266' 'P273' 'P277' 'P290' 'P297']\n",
      "Num for train:36\n",
      "\n",
      "['P066' 'P136' 'P168' 'P169' 'P172' 'P222' 'P270' 'P272']\n",
      "Num for test:8\n",
      "\n",
      "Num total:44\n",
      "\n",
      "4_fold\n",
      "idx4train:746 | idx4test:131 | total:877/877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5e35fea2324d33963aeffae3311c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  746\n",
      "Final shape: (746, 4242, 1), (746, 303, 1), (746, 303, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d018cf3c0c484cb3285ab02b98b7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  131\n",
      "Final shape: (131, 4242, 1), (131, 303, 1), (131, 303, 1)\n"
     ]
    }
   ],
   "source": [
    "# KFOLD 선언\n",
    "kfold = KFold(n_splits=5, random_state=seed_rand, shuffle=True)\n",
    "# 항상 피험자 명단을 kfold.split(여기)에 넣어야 됨\n",
    "countfold = -1\n",
    "print(f\"Total subject:{len(arrName)}\")\n",
    "print(f\"Total Data size:{len(listFromxlsx)}\")\n",
    "for train,test in kfold.split(arrName):\n",
    "    # 해당 fold numbering\n",
    "    countfold = countfold + 1\n",
    "    # 데이터 셋 만들기\n",
    "    # 이번 학습에 사용되는 피험자 명단\n",
    "    print(\"+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+\")\n",
    "    print(f\"Num. of fold: {countfold}\\n\")\n",
    "    print(f'{arrName[train]}\\nNum for train:{len(arrName[train])}\\n')\n",
    "    print(f'{arrName[test]}\\nNum for test:{len(arrName[test])}\\n')\n",
    "    print(f'Num total:{len(arrName[train])+len(arrName[test])}')\n",
    "\n",
    "    idx4train,idx4test = kfold2subfold(arrName,listFromxlsx,train,test)\n",
    "    print(f\"\\n{countfold}_fold\\nidx4train:{len(idx4train)} | idx4test:{len(idx4test)} | total:{len(idx4train)+len(idx4test)}/{len(listFromxlsx)}\")\n",
    "    # 전체 목록을 한번에 만들고 필요할 때마다 쓰도록 세팅\n",
    "    # 전체 데이터를 담고, 이걸 피험자 별로 추출할 수 있도록 만들기\n",
    "    columnsWOMAG = makeColumnsWOMAG()\n",
    "    X_columns = [str(i) for i in range(0,42)]\n",
    "    df_trainData_X = pd.DataFrame(columns=X_columns)\n",
    "\n",
    "    Y_columns = [str(i) for i in range(0,3)]\n",
    "    df_trainData_Y_angle = pd.DataFrame(columns=Y_columns) # angle은 3축\n",
    "    df_trainData_Y_moBWHT = pd.DataFrame(columns=Y_columns) # moment도 3축\n",
    "    \n",
    "    # Train 데이터에 해당하는 것만 담기!\n",
    "    # 아래와 동일하게 valid와 test 셋도 만들 수 있음!\n",
    "    for idx, datum in enumerate(tqdm([listFromFolder[i] for i in idx4train])):\n",
    "        df = pd.read_csv(join(TargetDir,datum))\n",
    "        # 데이터에서 일단 MAG 모두 제외하기\n",
    "        dfWOMAG = df.loc[:,columnsWOMAG]\n",
    "        # 측정된 moment 다리가 nonleg이면 그대로 file 두기\n",
    "        if listFromxlsx.loc[idx,'side'] == \"oaleg\":\n",
    "            targetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z']\n",
    "            nonTargetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "            otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z'] \n",
    "        else:\n",
    "            targetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "            nonTargetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z'] # mag 빼기\n",
    "            otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z']\n",
    "        # 데이터를 항상 동일한 순서로 만들기\n",
    "        concated = pd.concat([targetLegArr, nonTargetLegArr,otherArr],axis=1)\n",
    "\n",
    "        # rename하기\n",
    "        # 쌓아야 하니까..\n",
    "        concated.columns = X_columns\n",
    "        # input data 누적\n",
    "        df_trainData_X = pd.concat([df_trainData_X, concated],axis=0,ignore_index=True)\n",
    "        ##############################################################\n",
    "        # output data 만들기\n",
    "        # kinematic(Angle)\n",
    "        angle = dfWOMAG.loc[:,'ANGLE_X':'ANGLE_Z']\n",
    "        angle.columns = Y_columns\n",
    "        # output data 누적\n",
    "        df_trainData_Y_angle = pd.concat([df_trainData_Y_angle, angle],axis=0,ignore_index=True)\n",
    "        # kinetic(moment)\n",
    "        moBWHT = dfWOMAG.loc[:,'MOBWHT_X':'MOBWHT_Z']\n",
    "        moBWHT.columns = Y_columns\n",
    "        # output data 누적\n",
    "        df_trainData_Y_moBWHT = pd.concat([df_trainData_Y_moBWHT, moBWHT],axis=0,ignore_index=True)\n",
    "    # Scaler 적용\n",
    "    # 현재는 MInMaxscaler3D만 적용\n",
    "    scaler4X = MinMaxScaler() # Z-score nomalization\n",
    "    scaler4Y_angle = MinMaxScaler() # Z-score nomalization\n",
    "    scaler4Y_moBWHT  = MinMaxScaler() # Z-score nomalization\n",
    "\n",
    "    scaler4X.fit(df_trainData_X) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "    scaler4Y_angle.fit(df_trainData_Y_angle) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "    scaler4Y_moBWHT.fit(df_trainData_Y_moBWHT) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "\n",
    "    scaled_X_train = scaler4X.transform(df_trainData_X)\n",
    "    scaled_Y_angle_train = scaler4Y_angle.transform(df_trainData_Y_angle)\n",
    "    scaled_Y_moBWHT_train = scaler4Y_moBWHT.transform(df_trainData_Y_moBWHT)\n",
    "\n",
    "    # scaler 저장 위치\n",
    "    scalerDir = join(dataDir, r'SAVE_dataSet',nameDataset)\n",
    "    make_dir(scalerDir)\n",
    "    # scaler 저장\n",
    "    dump(scaler4X, open(join(scalerDir,f\"{countfold}_fold_scaler4X.pkl\"), 'wb'))\n",
    "    dump(scaler4Y_angle, open(join(scalerDir,f'{countfold}_fold_scaler4Y_angle.pkl'), 'wb'))\n",
    "    dump(scaler4Y_moBWHT, open(join(scalerDir,f'{countfold}_fold_scaler4Y_moBWHT.pkl'), 'wb'))\n",
    "\n",
    "    # 이제 제대로 scaling 했으니까 원상복구 하자!\n",
    "    # 원하는 shape 형태 \n",
    "    # (N, 4242, 1), (N, 303, 1), (N, 303, 1)   N 은 데이터 수\n",
    "    X_train = []\n",
    "    Y_angle_train = []\n",
    "    Y_moBWHT_train = []\n",
    "    for i in range(0,len(idx4train)):\n",
    "        chopped_X_train = scaled_X_train[i*101:101+i*101,:]\n",
    "        X_train.append(chopped_X_train.flatten('F').reshape(-1,1))\n",
    "        \n",
    "        chopped_Y_angle_train= scaled_Y_angle_train[i*101:101+i*101,:]\n",
    "        Y_angle_train.append(chopped_Y_angle_train.flatten('F').reshape(-1,1))\n",
    "\n",
    "        chopped_Y_moBWHT_train= scaled_Y_moBWHT_train[i*101:101+i*101,:]\n",
    "        Y_moBWHT_train.append(chopped_Y_moBWHT_train.flatten('F').reshape(-1,1))\n",
    "\n",
    "    final_X_train = np.array(X_train)\n",
    "    final_Y_angle_train = np.array(Y_angle_train)\n",
    "    final_Y_moBWHT_train = np.array(Y_moBWHT_train)\n",
    "\n",
    "    # 만들어진 데이터 shape 확인! \n",
    "    print(f'TRAIN data  :  {len(idx4train)}')\n",
    "    print(f'Final shape: {final_X_train.shape}, {final_Y_angle_train.shape}, {final_Y_moBWHT_train.shape}')\n",
    "\n",
    "    # 데이터 저장 위치\n",
    "    setDir = join(dataDir, r'SAVE_dataSet',nameDataset)\n",
    "    make_dir(setDir)\n",
    "    # 데이터 저장\n",
    "    savez_compressed(join(setDir,f\"{countfold}_fold_final_train.npz\"), final_X_train=final_X_train,final_Y_angle_train=final_Y_angle_train,final_Y_moBWHT_train=final_Y_moBWHT_train)\n",
    "    \n",
    "    #############################################################################################################################################\n",
    "    #test set 용\n",
    "    # 전체 목록을 한번에 만들고 필요할 때마다 쓰도록 세팅\n",
    "    # 전체 데이터를 담고, 이걸 피험자 별로 추출할 수 있도록 만들기\n",
    "    columnsWOMAG = makeColumnsWOMAG()\n",
    "    X_columns = [str(i) for i in range(0,42)]\n",
    "    df_testData_X = pd.DataFrame(columns=X_columns)\n",
    "\n",
    "    Y_columns = [str(i) for i in range(0,3)]\n",
    "    df_testData_Y_angle = pd.DataFrame(columns=Y_columns) # angle은 3축\n",
    "    df_testData_Y_moBWHT = pd.DataFrame(columns=Y_columns) # moment도 3축\n",
    "    # test 데이터에 해당하는 것만 담기!\n",
    "    # 아래와 동일하게 valid와 test 셋도 만들 수 있음!\n",
    "    for idx, datum in enumerate(tqdm([listFromFolder[i] for i in idx4test])):\n",
    "        df = pd.read_csv(join(TargetDir,datum))\n",
    "        # 데이터에서 일단 MAG 모두 제외하기\n",
    "        dfWOMAG = df.loc[:,columnsWOMAG]\n",
    "        # 측정된 moment 다리가 nonleg이면 그대로 file 두기\n",
    "        if listFromxlsx.loc[idx,'side'] == \"oaleg\":\n",
    "            targetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z']\n",
    "            nonTargetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "            otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z'] \n",
    "        else:\n",
    "            targetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "            nonTargetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z'] # mag 빼기\n",
    "            otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z']\n",
    "        # 데이터를 항상 동일한 순서로 만들기\n",
    "        concated = pd.concat([targetLegArr, nonTargetLegArr,otherArr],axis=1)\n",
    "\n",
    "        # rename하기\n",
    "        # 쌓아야 하니까..\n",
    "        concated.columns = X_columns\n",
    "        # input data 누적\n",
    "        df_testData_X = pd.concat([df_testData_X, concated],axis=0,ignore_index=True)\n",
    "        ##############################################################\n",
    "        # output data 만들기\n",
    "        # kinematic(Angle)\n",
    "        angle = dfWOMAG.loc[:,'ANGLE_X':'ANGLE_Z']\n",
    "        angle.columns = Y_columns\n",
    "        # output data 누적\n",
    "        df_testData_Y_angle = pd.concat([df_testData_Y_angle, angle],axis=0,ignore_index=True)\n",
    "        # kinetic(moment)\n",
    "        moBWHT = dfWOMAG.loc[:,'MOBWHT_X':'MOBWHT_Z']\n",
    "        moBWHT.columns = Y_columns\n",
    "        # output data 누적\n",
    "        df_testData_Y_moBWHT = pd.concat([df_testData_Y_moBWHT, moBWHT],axis=0,ignore_index=True)\n",
    "    \n",
    "    # Scaler 적용\n",
    "    # 현재는 MInMaxscaler3D만 적용\n",
    "    scaled_X_test = scaler4X.transform(df_testData_X)\n",
    "    scaled_Y_angle_test = scaler4Y_angle.transform(df_testData_Y_angle)\n",
    "    scaled_Y_moBWHT_test = scaler4Y_moBWHT.transform(df_testData_Y_moBWHT)\n",
    "    \n",
    "    # 이제 제대로 scaling 했으니까 원상복구 하자!\n",
    "    # 원하는 shape 형태 \n",
    "    # (N, 4242, 1), (N, 303, 1), (N, 303, 1)   N 은 데이터 수\n",
    "    X_test = []\n",
    "    Y_angle_test = []\n",
    "    Y_moBWHT_test = []\n",
    "    for i in range(0,len(idx4test)):\n",
    "        chopped_X_test = scaled_X_test[i*101:101+i*101,:]\n",
    "        X_test.append(chopped_X_test.flatten('F').reshape(-1,1))\n",
    "        \n",
    "        chopped_Y_angle_test= scaled_Y_angle_test[i*101:101+i*101,:]\n",
    "        Y_angle_test.append(chopped_Y_angle_test.flatten('F').reshape(-1,1))\n",
    "\n",
    "        chopped_Y_moBWHT_test= scaled_Y_moBWHT_test[i*101:101+i*101,:]\n",
    "        Y_moBWHT_test.append(chopped_Y_moBWHT_test.flatten('F').reshape(-1,1))\n",
    "\n",
    "    final_X_test = np.array(X_test)\n",
    "    final_Y_angle_test = np.array(Y_angle_test)\n",
    "    final_Y_moBWHT_test = np.array(Y_moBWHT_test)\n",
    "\n",
    "    # 만들어진 데이터 shape 확인! \n",
    "    print(f'TEST data  :  {len(idx4test)}')\n",
    "    print(f'Final shape: {final_X_test.shape}, {final_Y_angle_test.shape}, {final_Y_moBWHT_test.shape}')\n",
    "\n",
    "    # 데이터 저장 위치\n",
    "    # train 데이터와 동일\n",
    "    # 데이터 저장\n",
    "    savez_compressed(join(setDir,f\"{countfold}_fold_final_test.npz\"), final_X_test=final_X_test,final_Y_angle_test=final_Y_angle_test,final_Y_moBWHT_test=final_Y_moBWHT_test)\n",
    "    # 이후에 삭제하든 함수로 만들든 할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개별 K-fold 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mz:\\PROJECTS\\iwalqq\\Data\\V3D\\Output\\IMU Deep Learning\\IMUforKnee\\preperation\\4_DataSet_CAN_MYWAY.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/PROJECTS/iwalqq/Data/V3D/Output/IMU%20Deep%20Learning/IMUforKnee/preperation/4_DataSet_CAN_MYWAY.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m# KFOLD 선언\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/z%3A/PROJECTS/iwalqq/Data/V3D/Output/IMU%20Deep%20Learning/IMUforKnee/preperation/4_DataSet_CAN_MYWAY.ipynb#ch0000012?line=1'>2</a>\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m41\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/PROJECTS/iwalqq/Data/V3D/Output/IMU%20Deep%20Learning/IMUforKnee/preperation/4_DataSet_CAN_MYWAY.ipynb#ch0000012?line=2'>3</a>\u001b[0m \u001b[39m# 항상 피험자 명단을 kfold.split(여기)에 넣어야 됨\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/z%3A/PROJECTS/iwalqq/Data/V3D/Output/IMU%20Deep%20Learning/IMUforKnee/preperation/4_DataSet_CAN_MYWAY.ipynb#ch0000012?line=3'>4</a>\u001b[0m countfold \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "# KFOLD 선언\n",
    "kfold = KFold(n_splits=5, random_state=41, shuffle=True)\n",
    "# 항상 피험자 명단을 kfold.split(여기)에 넣어야 됨\n",
    "countfold = -1\n",
    "for train,test in kfold.split(arrName):\n",
    "    # 해당 fold numbering\n",
    "    countfold = countfold + 1\n",
    "    # 데이터 셋 만들기\n",
    "    # 이번 학습에 사용되는 피험자 명단\n",
    "    print(f\"Num. of fold: {countfold}\")\n",
    "    print(f'{arrName[train]}\\nNum for train:{len(arrName[train])}')\n",
    "    print(f'{arrName[test]}\\nNum for test:{len(arrName[test])}')\n",
    "    print(f'Num total:{len(arrName[train])+len(arrName[test])}')\n",
    "\n",
    "    idx4train,idx4test = kfold2subfold(arrName,listFromxlsx,train,test)\n",
    "    \n",
    "    break\n",
    "    # 이후에 삭제하든 함수로 만들든 할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 155)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx4train), len(idx4test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 목록을 한번에 만들고 필요할 때마다 쓰도록 세팅\n",
    "# 전체 데이터를 담고, 이걸 피험자 별로 추출할 수 있도록 만들기\n",
    "columnsWOMAG = makeColumnsWOMAG()\n",
    "X_columns = [str(i) for i in range(0,42)]\n",
    "df_trainData_X = pd.DataFrame(columns=X_columns)\n",
    "\n",
    "Y_columns = [str(i) for i in range(0,3)]\n",
    "df_trainData_Y_angle = pd.DataFrame(columns=Y_columns) # angle은 3축\n",
    "df_trainData_Y_moBWHT = pd.DataFrame(columns=Y_columns) # moment도 3축\n",
    "# Train 데이터에 해당하는 것만 담기!\n",
    "# 아래와 동일하게 valid와 test 셋도 만들 수 있음!\n",
    "for idx, datum in enumerate(tqdm([listFromFolder[i] for i in idx4train])):\n",
    "    df = pd.read_csv(join(TargetDir,datum))\n",
    "    # 데이터에서 일단 MAG 모두 제외하기\n",
    "    dfWOMAG = df.loc[:,columnsWOMAG]\n",
    "    # 측정된 moment 다리가 nonleg이면 그대로 file 두기\n",
    "    if listFromxlsx.loc[idx,'side'] == \"oaleg\":\n",
    "        targetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z']\n",
    "        nonTargetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "        otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z'] \n",
    "    else:\n",
    "        targetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "        nonTargetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z'] # mag 빼기\n",
    "        otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z']\n",
    "    # 데이터를 항상 동일한 순서로 만들기\n",
    "    concated = pd.concat([targetLegArr, nonTargetLegArr,otherArr],axis=1)\n",
    "\n",
    "    # rename하기\n",
    "    # 쌓아야 하니까..\n",
    "    concated.columns = X_columns\n",
    "    # input data 누적\n",
    "    df_trainData_X = pd.concat([df_trainData_X, concated],axis=0,ignore_index=True)\n",
    "    ##############################################################\n",
    "    # output data 만들기\n",
    "    # kinematic(Angle)\n",
    "    angle = dfWOMAG.loc[:,'ANGLE_X':'ANGLE_Z']\n",
    "    angle.columns = Y_columns\n",
    "    # output data 누적\n",
    "    df_trainData_Y_angle = pd.concat([df_trainData_Y_angle, angle],axis=0,ignore_index=True)\n",
    "    # kinetic(moment)\n",
    "    moBWHT = dfWOMAG.loc[:,'MOBWHT_X':'MOBWHT_Z']\n",
    "    moBWHT.columns = Y_columns\n",
    "    # output data 누적\n",
    "    df_trainData_Y_moBWHT = pd.concat([df_trainData_Y_moBWHT, moBWHT],axis=0,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler 적용\n",
    "# 현재는 MInMaxscaler3D만 적용\n",
    "scaler4X = MinMaxScaler() # Z-score nomalization\n",
    "scaler4Y_angle = MinMaxScaler() # Z-score nomalization\n",
    "scaler4Y_moBWHT  = MinMaxScaler() # Z-score nomalization\n",
    "\n",
    "\n",
    "scaler4X.fit(df_trainData_X) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "scaler4Y_angle.fit(df_trainData_Y_angle) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "scaler4Y_moBWHT.fit(df_trainData_Y_moBWHT) # ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!ONLY FOR TRAIN DATA!!!!\n",
    "\n",
    "scaled_X_train = scaler4X.transform(df_trainData_X)\n",
    "scaled_Y_angle_train = scaler4Y_angle.transform(df_trainData_Y_angle)\n",
    "scaled_Y_moBWHT_train = scaler4Y_moBWHT.transform(df_trainData_Y_moBWHT)\n",
    "\n",
    "# scaler 저장 위치\n",
    "scalerDir = join(dataDir, r'SAVE_fittedScaler')\n",
    "make_dir(scalerDir)\n",
    "# scaler 저장\n",
    "# https://wooono.tistory.com/360\n",
    "dump(scaler4X, open(join(scalerDir,f\"{countfold}_fold_scaler4X.pkl\"), 'wb'))\n",
    "dump(scaler4Y_angle, open(join(scalerDir,f'{countfold}_fold_scaler4Y_angle.pkl'), 'wb'))\n",
    "dump(scaler4Y_moBWHT, open(join(scalerDir,f'{countfold}_fold_scaler4Y_moBWHT.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 제대로 scaling 했으니까 원상복구 하자!\n",
    "# 원하는 shape 형태 \n",
    "# (N, 4242, 1), (N, 303, 1), (N, 303, 1)   N 은 데이터 수\n",
    "X_train = []\n",
    "Y_angle_train = []\n",
    "Y_moBWHT_train = []\n",
    "for i in range(0,len(idx4train)):\n",
    "    chopped_X_train = scaled_X_train[i*101:101+i*101,:]\n",
    "    X_train.append(chopped_X_train.flatten('F').reshape(-1,1))\n",
    "    \n",
    "    chopped_Y_angle_train= scaled_Y_angle_train[i*101:101+i*101,:]\n",
    "    Y_angle_train.append(chopped_Y_angle_train.flatten('F').reshape(-1,1))\n",
    "\n",
    "    chopped_Y_moBWHT_train= scaled_Y_moBWHT_train[i*101:101+i*101,:]\n",
    "    Y_moBWHT_train.append(chopped_Y_moBWHT_train.flatten('F').reshape(-1,1))\n",
    "\n",
    "final_X_train = np.array(X_train)\n",
    "final_Y_angle_train = np.array(Y_angle_train)\n",
    "final_Y_moBWHT_train = np.array(Y_moBWHT_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN data  :  722\n",
      "Final shape: (722, 4242, 1), (722, 303, 1), (722, 303, 1)\n"
     ]
    }
   ],
   "source": [
    "# 만들어진 데이터 shape 확인! \n",
    "print(f'TRAIN data  :  {len(idx4train)}')\n",
    "print(f'Final shape: {final_X_train.shape}, {final_Y_angle_train.shape}, {final_Y_moBWHT_train.shape}')\n",
    "\n",
    "# 데이터 저장 위치\n",
    "setDir = join(dataDir, r'SAVE_dataSet')\n",
    "make_dir(setDir)\n",
    "# 데이터 저장\n",
    "# https://machinelearningmastery.com/how-to-save-a-numpy-array-to-file-for-machine-learning/\n",
    "savez_compressed(join(setDir,f\"{countfold}_fold_final_train.npz\"), final_X_train=final_X_train,final_Y_angle_train=final_Y_angle_train,final_Y_moBWHT_train=final_Y_moBWHT_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded Final shape: (722, 4242, 1), (722, 303, 1), (722, 303, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 확인\n",
    "loaded_train = np.load(join(setDir,f\"{countfold}_fold_final_train.npz\"))\n",
    "print(f'loaded Final shape: {loaded_train[\"final_X_train\"].shape}, {loaded_train[\"final_Y_angle_train\"].shape}, {loaded_train[\"final_Y_moBWHT_train\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 발표용 데이터\n",
    "if True:\n",
    "    pd.DataFrame(final_X_train[0]).to_csv(\"CBD_IMU_1.csv\",index=False)\n",
    "    pd.DataFrame(final_Y_angle_train[0]).to_csv(\"CBD_angle_1.csv\",index=False)\n",
    "    pd.DataFrame(final_Y_moBWHT_train[0]).to_csv(\"CBD_moBWHT_1.csv\",index=False)\n",
    "\n",
    "    reshaped = final_X_train[0].reshape(-1,42, order='F') # 원래 데이터로 복구할 때!! 잘 된것 확인함!\n",
    "    result = scaler4X.inverse_transform(reshaped)\n",
    "    pd.DataFrame(result).to_csv(\"CBD_IMU_rescaled_1.csv\",index=False)\n",
    "    \n",
    "    reshaped = final_Y_angle_train[0].reshape(-1,3, order='F') # 원래 데이터로 복구할 때!!\n",
    "    result = scaler4Y_angle.inverse_transform(reshaped)\n",
    "    pd.DataFrame(result).to_csv(\"CBD_angle_rescaled_1.csv\",index=False)\n",
    "\n",
    "    reshaped = final_Y_moBWHT_train[0].reshape(-1,3, order='F') # 원래 데이터로 복구할 때!!\n",
    "    result = scaler4Y_moBWHT.inverse_transform(reshaped)\n",
    "    pd.DataFrame(result).to_csv(\"CBD_moBWHT_rescaled_1.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741262a6aee4696a2b7aff305cf2c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전체 목록을 한번에 만들고 필요할 때마다 쓰도록 세팅\n",
    "# 전체 데이터를 담고, 이걸 피험자 별로 추출할 수 있도록 만들기\n",
    "columnsWOMAG = makeColumnsWOMAG()\n",
    "X_columns = [str(i) for i in range(0,42)]\n",
    "df_testData_X = pd.DataFrame(columns=X_columns)\n",
    "\n",
    "Y_columns = [str(i) for i in range(0,3)]\n",
    "df_testData_Y_angle = pd.DataFrame(columns=Y_columns) # angle은 3축\n",
    "df_testData_Y_moBWHT = pd.DataFrame(columns=Y_columns) # moment도 3축\n",
    "# test 데이터에 해당하는 것만 담기!\n",
    "# 아래와 동일하게 valid와 test 셋도 만들 수 있음!\n",
    "for idx, datum in enumerate(tqdm([listFromFolder[i] for i in idx4test])):\n",
    "    df = pd.read_csv(join(TargetDir,datum))\n",
    "    # 데이터에서 일단 MAG 모두 제외하기\n",
    "    dfWOMAG = df.loc[:,columnsWOMAG]\n",
    "    # 측정된 moment 다리가 nonleg이면 그대로 file 두기\n",
    "    if listFromxlsx.loc[idx,'side'] == \"oaleg\":\n",
    "        targetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z']\n",
    "        nonTargetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "        otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z'] \n",
    "    else:\n",
    "        targetLegArr = dfWOMAG.loc[:,'non_shank_ACC_X':'non_thigh_GYRO_Z'] # mag 빼기\n",
    "        nonTargetLegArr = dfWOMAG.loc[:,'oa_shank_ACC_X':'oa_thigh_GYRO_Z'] # mag 빼기\n",
    "        otherArr = dfWOMAG.loc[:,'trunk_ACC_X':'trunk_GYRO_Z']\n",
    "    # 데이터를 항상 동일한 순서로 만들기\n",
    "    concated = pd.concat([targetLegArr, nonTargetLegArr,otherArr],axis=1)\n",
    "\n",
    "    # rename하기\n",
    "    # 쌓아야 하니까..\n",
    "    concated.columns = X_columns\n",
    "    # input data 누적\n",
    "    df_testData_X = pd.concat([df_testData_X, concated],axis=0,ignore_index=True)\n",
    "    ##############################################################\n",
    "    # output data 만들기\n",
    "    # kinematic(Angle)\n",
    "    angle = dfWOMAG.loc[:,'ANGLE_X':'ANGLE_Z']\n",
    "    angle.columns = Y_columns\n",
    "    # output data 누적\n",
    "    df_testData_Y_angle = pd.concat([df_testData_Y_angle, angle],axis=0,ignore_index=True)\n",
    "    # kinetic(moment)\n",
    "    moBWHT = dfWOMAG.loc[:,'MOBWHT_X':'MOBWHT_Z']\n",
    "    moBWHT.columns = Y_columns\n",
    "    # output data 누적\n",
    "    df_testData_Y_moBWHT = pd.concat([df_testData_Y_moBWHT, moBWHT],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler 적용\n",
    "# 현재는 MInMaxscaler3D만 적용\n",
    "scaled_X_test = scaler4X.transform(df_testData_X)\n",
    "scaled_Y_angle_test = scaler4Y_angle.transform(df_testData_Y_angle)\n",
    "scaled_Y_moBWHT_test = scaler4Y_moBWHT.transform(df_testData_Y_moBWHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 제대로 scaling 했으니까 원상복구 하자!\n",
    "# 원하는 shape 형태 \n",
    "# (N, 4242, 1), (N, 303, 1), (N, 303, 1)   N 은 데이터 수\n",
    "X_test = []\n",
    "Y_angle_test = []\n",
    "Y_moBWHT_test = []\n",
    "for i in range(0,len(idx4test)):\n",
    "    chopped_X_test = scaled_X_test[i*101:101+i*101,:]\n",
    "    X_test.append(chopped_X_test.flatten('F').reshape(-1,1))\n",
    "    \n",
    "    chopped_Y_angle_test= scaled_Y_angle_test[i*101:101+i*101,:]\n",
    "    Y_angle_test.append(chopped_Y_angle_test.flatten('F').reshape(-1,1))\n",
    "\n",
    "    chopped_Y_moBWHT_test= scaled_Y_moBWHT_test[i*101:101+i*101,:]\n",
    "    Y_moBWHT_test.append(chopped_Y_moBWHT_test.flatten('F').reshape(-1,1))\n",
    "\n",
    "final_X_test = np.array(X_test)\n",
    "final_Y_angle_test = np.array(Y_angle_test)\n",
    "final_Y_moBWHT_test = np.array(Y_moBWHT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST data  :  155\n",
      "Final shape: (155, 4242, 1), (155, 303, 1), (155, 303, 1)\n"
     ]
    }
   ],
   "source": [
    "# 만들어진 데이터 shape 확인! \n",
    "print(f'TEST data  :  {len(idx4test)}')\n",
    "print(f'Final shape: {final_X_test.shape}, {final_Y_angle_test.shape}, {final_Y_moBWHT_test.shape}')\n",
    "\n",
    "# 데이터 저장 위치\n",
    "setDir = join(dataDir, r'SAVE_dataSet')\n",
    "make_dir(setDir)\n",
    "# 데이터 저장\n",
    "savez_compressed(join(setDir,f\"{countfold}_fold_final_test.npz\"), final_X_test=final_X_test,final_Y_angle_test=final_Y_angle_test,final_Y_moBWHT_test=final_Y_moBWHT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded Final shape: (155, 4242, 1), (155, 303, 1), (155, 303, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기 확인\n",
    "loaded_train = np.load(join(setDir,f\"{countfold}_fold_final_test.npz\"))\n",
    "print(f'loaded Final shape: {loaded_train[\"final_X_test\"].shape}, {loaded_train[\"final_Y_angle_test\"].shape}, {loaded_train[\"final_Y_moBWHT_test\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로 배운 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4242, 1), (101, 42, 1))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape 하는 법\n",
    "flat_concat.shape, concated.to_numpy().reshape(101,42,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), (4, 3))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array( [ [1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "a[0,:],a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.08866167, -1.6116709 , -1.12578921, -0.69913567, -0.31552896,\n",
       "        0.01626456,  0.2934858 ,  0.49830202,  0.62481276,  0.67396727,\n",
       "        0.66056931,  0.60059968,  0.50080002,  0.36252644,  0.18663478,\n",
       "       -0.0244365 , -0.26707541, -0.52839363, -0.78795609, -1.01967686,\n",
       "       -1.20064522, -1.31313809, -1.34727698, -1.30148371, -1.18328261,\n",
       "       -1.01031294, -0.80652645, -0.59887084, -0.41240249, -0.26469963,\n",
       "       -0.1639805 , -0.11075129, -0.09801369, -0.11699963, -0.1552758 ,\n",
       "       -0.19970287, -0.2355143 , -0.24934117, -0.23495442, -0.19335586,\n",
       "       -0.13348058, -0.066768  , -0.00379263,  0.04791029,  0.08493437,\n",
       "        0.10705636,  0.1168679 ,  0.11778726,  0.1139358 ,  0.10917843,\n",
       "        0.10651575,  0.10806219,  0.11395871,  0.12298314,  0.13297936,\n",
       "        0.14167265,  0.14704517,  0.14762067,  0.14238325,  0.13102786,\n",
       "        0.11354904,  0.09108217,  0.06584669,  0.04045179,  0.01679698,\n",
       "       -0.00449873, -0.02328051, -0.03918528, -0.0509166 , -0.05659852,\n",
       "       -0.05403333, -0.04182458, -0.01860489,  0.01560236,  0.0597202 ,\n",
       "        0.11148928,  0.16782661,  0.22637405,  0.28447062,  0.34224201,\n",
       "        0.39966642,  0.45754159,  0.5165377 ,  0.57683125,  0.63907464,\n",
       "        0.7016639 ,  0.76295203,  0.81993773,  0.86906512,  0.90632289,\n",
       "        0.92722147,  0.92593681,  0.89690778,  0.83346197,  0.7289472 ,\n",
       "        0.58455905,  0.39661491,  0.18008911, -0.07270238, -0.32650802,\n",
       "       -0.60742325])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape은 (행, 렬, 갯수) 순으로 해야 맞음\n",
    "# concated 는 101행, 42열로 구성됨\n",
    "concated.to_numpy().reshape(101,42,1)[:,0,0] # 올바른 방향으로 읽어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P002' 'P007' 'P017' 'P029' 'P061' 'P065' 'P069' 'P104' 'P105' 'P106'\n",
      " 'P115' 'P119' 'P121' 'P135' 'P147' 'P149' 'P155' 'P168' 'P169' 'P172'\n",
      " 'P196' 'P203' 'P222' 'P225' 'P229' 'P243' 'P245' 'P258' 'P263' 'P266'\n",
      " 'P270' 'P272' 'P273' 'P277' 'P290']\n",
      "['P050' 'P066' 'P132' 'P134' 'P136' 'P142' 'P205' 'P226' 'P297']\n",
      "35,9\n",
      "+++++++++++\n",
      "['P002' 'P007' 'P017' 'P029' 'P061' 'P065' 'P069' 'P104' 'P105' 'P106'\n",
      " 'P115' 'P119' 'P121' 'P135' 'P147' 'P169' 'P172' 'P203' 'P225' 'P229'\n",
      " 'P243' 'P245' 'P258' 'P266' 'P270' 'P272' 'P273' 'P290']\n",
      "['P149' 'P155' 'P168' 'P196' 'P222' 'P263' 'P277']\n",
      "28,7\n"
     ]
    }
   ],
   "source": [
    "# train valid test로 두번 쪼개야 할때\n",
    "arrName = np.array(['P002', 'P007', 'P017', 'P029', 'P050', 'P061', 'P065', 'P066',\n",
    "       'P069', 'P104', 'P105', 'P106', 'P115', 'P119', 'P121', 'P132',\n",
    "       'P134', 'P135', 'P136', 'P142', 'P147', 'P149', 'P155', 'P168',\n",
    "       'P169', 'P172', 'P196', 'P203', 'P205', 'P222', 'P225', 'P226',\n",
    "       'P229', 'P243', 'P245', 'P258', 'P263', 'P266', 'P270', 'P272',\n",
    "       'P273', 'P277', 'P290', 'P297'])\n",
    "# kfold를 위한 사전작업\n",
    "# subejct 별로 fold가 가능하게 하기\n",
    "# 일단 KFOLD 선언\n",
    "kfold = KFold(n_splits=5, random_state=4, shuffle=True)\n",
    "\n",
    "# 항상 피험자 명단을 kfold.split에 넣어야 됨\n",
    "for train_whole,test in kfold.split(arrName):\n",
    "    # 데이터 셋 만들기\n",
    "    # 이번 학습에 사용되는 피험자 명딘\n",
    "    print(arrName[train_whole])\n",
    "    print(arrName[test])\n",
    "    print(f'{len(arrName[train_whole])},{len(arrName[test])}')\n",
    "    print(\"+++++++++++\")\n",
    "    break\n",
    "\n",
    "arrTWhole = arrName[train_whole]\n",
    "for train,valid in kfold.split(arrTWhole):\n",
    "    print(arrTWhole[train])\n",
    "    print(arrTWhole[valid])\n",
    "    print(f'{len(arrTWhole[train])},{len(arrName[valid])}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "# gob bless this programmer..\n",
    "# scaling하는 순서\n",
    "X_tmp = X_train.copy()\n",
    "# 선언\n",
    "scaler = StandardScaler3D()\n",
    "# fitting\n",
    "scaler.fit(X_tmp)\n",
    "# scaler 적용@\n",
    "scaled_X_tmp = scaler.transform(X_tmp)\n",
    "# scaler 역변환\n",
    "rescaeld_X_tmp = scaler.inverse_transform(scaled_X_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833b58c5ff5abdd4ad28d40373cf4d49bbb57d9ec65bbe609aaeb188a76179b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('buIMU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
