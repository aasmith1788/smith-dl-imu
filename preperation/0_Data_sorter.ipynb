{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (8.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asmith8\\.conda\\envs\\imu_env39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# import 필요한 라이브러리\n",
    "!pip install natsort\n",
    "!pip install pandas\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the patient ID to uppercase.\n",
    "The consistency of IDs is very important!\n",
    "Always check that every file follows the format below.\n",
    "\n",
    "fileName: P002_031220_w_0001_nonleg_imu_knee_angle_moment.csv\n",
    "\n",
    "meaning:  patientID_visitDate_speed_Numbering_measuredLeg_imu_knee_angle_moment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files with patient IDs\n",
    "targetDir = \"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\CSV\\exported_csv\"\n",
    "\n",
    "# Loop through all files in the target directory\n",
    "# natsorted() ensures natural sorting (p1, p2, p10 instead of p1, p10, p2)\n",
    "for filename in natsorted(os.listdir(targetDir)):\n",
    "    \n",
    "    # Create the full path to the current file\n",
    "    old_name = os.path.join(targetDir, filename)\n",
    "    \n",
    "    # Create the new filename by replacing the first character with 'P'\n",
    "    # This assumes all files start with 'p' and we want to change it to 'P'\n",
    "    # filename[1:] takes everything after the first character\n",
    "    new_name = os.path.join(targetDir, 'P' + filename[1:])\n",
    "    \n",
    "    # Rename the file from old_name to new_name\n",
    "    os.rename(old_name, new_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# txt To csv conversion\n",
    "# Essential\n",
    "# Always perform when receiving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt to csv convert\n",
    "txtDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\20220325_raw_byDeepak\"\n",
    "csvDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\20220325_raw_byDeepak_csv\"\n",
    "# Get naturally sorted list of all files in the source directory\n",
    "dataList = natsorted([_ for _ in os.listdir(txtDir)])\n",
    "for Name_datum in dataList:\n",
    "    # Read the .txt file as tab-separated values\n",
    "    read_file = pd.read_csv(os.path.join(txtDir, Name_datum),sep='\\t')\n",
    "    # Save as .csv file with extension changed from .txt to .csv\n",
    "    read_file.to_csv(os.path.join(csvDir, Name_datum.replace(\".txt\",\".csv\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When converting TXT to CSV, place the ‘side’ field of oaleg at the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt to csv convert\n",
    "txtDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\20220325_raw_byDeepak\"\n",
    "csvDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\allnew_20220325_raw_byDeepak_csv\"\n",
    "dgDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\demographics.xlsx\"\n",
    "# Get naturally sorted list of all files in the source directory\n",
    "dataList = natsorted([_ for _ in os.listdir(txtDir)])\n",
    "# demographic 관련 - Load demographics Excel file\n",
    "list_demograph = pd.read_excel(dgDir,engine = 'openpyxl')\n",
    "for Name_datum in dataList:\n",
    "    # Extract patient ID from filename (part before first underscore) and lookup 'Side' info\n",
    "    sideInfo = list_demograph.loc[list_demograph['ID']==Name_datum.split('_')[0],'Side']\n",
    "    # Read the .txt file as tab-separated values\n",
    "    read_file = pd.read_csv(os.path.join(txtDir, Name_datum),sep='\\t')\n",
    "    # Change file extension from .txt to .csv\n",
    "    filename =  Name_datum.replace(\".txt\",\".csv\")\n",
    "    # Add side information to filename: \"filename_Left.csv\" or \"filename_Right.csv\"\n",
    "    filename = '.'.join([filename.split('.')[0]+f'_{sideInfo.values[0]}',filename.split('.')[1]])\n",
    "    # Save the file with the new filename that includes side information\n",
    "    read_file.to_csv(os.path.join(csvDir,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sideInfo.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the CSV files into separate sub-folders within one main folder.\n",
    "Not needed at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the necessary functions.\n",
    "def ensure_dir(file_path):\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "# Specify target directory\n",
    "dataDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\CSV\"\n",
    "sortedFolder = \"sorted_csv\"\n",
    "dataExt = r\".csv\"\n",
    "\n",
    "# Retrieve the full list of files, select only the required extensions, and from that list keep only the .csv files while excluding everything else.\n",
    "dataList = natsorted([_ for _ in os.listdir(os.path.join(dataDir,\"exported_csv\")) if _.endswith(dataExt)])\n",
    "countForErr = 0\n",
    "\n",
    "# Split the file names, and then move each part into its own folder.\n",
    "for datum in dataList:\n",
    "    try:\n",
    "        # Split filename by underscores to extract patient information\n",
    "        # Example: \"P001_20220325_Left_Affected_Fast.csv\" becomes [\"P001\", \"20220325\", \"Left\", \"Affected\", \"Fast.csv\"]\n",
    "        sep_datum = datum.split(\"_\")\n",
    "        paName = sep_datum[0]          # Patient name/ID (e.g., \"P001\")\n",
    "        paVisitDate = sep_datum[1]     # Visit date (e.g., \"20220325\")\n",
    "        paAffectedside = sep_datum[2]  # Affected side (e.g., \"Left\")\n",
    "        paDataside = sep_datum[3]      # Data side (e.g., \"Affected\")\n",
    "        paSpeed = sep_datum[4]         # Speed condition (e.g., \"Fast.csv\")\n",
    "        \n",
    "        # Required path - create nested folder structure based on file components\n",
    "        # Result: CSV/sorted_csv/P001/20220325/Affected/Fast.csv/\n",
    "        saveDir = os.path.join(dataDir, sortedFolder, paName, paVisitDate, paDataside, paSpeed)\n",
    "        \n",
    "        # Check path - create the directory structure if it doesn't exist\n",
    "        ensure_dir(saveDir)\n",
    "        \n",
    "        # Move file - copy the file to the new organized location\n",
    "        if not os.path.exists(os.path.join(saveDir,datum)): # If file already exists, skip it\n",
    "            shutil.copyfile(os.path.join(dataDir,\"exported_csv\", datum), os.path.join(saveDir,datum))\n",
    "    except IndexError:\n",
    "        # Handle files that don't have the expected underscore structure\n",
    "        countForErr = countForErr + 1\n",
    "        print(f'pass the weird file:{countForErr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data classified into folders into one (just in case)\n",
    "# Currently not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed folders back into a single file\n",
    "# Find all .csv files within the folder\n",
    "dataDir = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\sorted_csv\"\n",
    "exportFolder = r\"R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\exported_csv\"\n",
    "\n",
    "# Walk through all subdirectories and files in the sorted folder structure\n",
    "for (path, dir, files) in os.walk(dataDir):\n",
    "    for filename in files:\n",
    "        # Extract file extension to check if it's a CSV file\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.csv':\n",
    "            # Copy the CSV file from nested folder back to flat export folder\n",
    "            shutil.copyfile(os.path.join(path, filename), os.path.join(exportFolder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to exclude - first filter out columns with anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases where column length is short\n",
    "# Continuing from the next code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deaecf69fdd75db6910ee7dbdef1256191e6e0ba8ec080482b87a38c123d274f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
