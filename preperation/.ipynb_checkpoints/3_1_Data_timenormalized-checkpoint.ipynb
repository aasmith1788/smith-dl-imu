{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is used to time-normalize input data after running the 3_0 code!\n",
    "# Load the filtered data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 library\n",
    "import os\n",
    "from re import A\n",
    "import subprocess\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "import keyboard\n",
    "import signal\n",
    "import subprocess\n",
    "import psutil\n",
    "import math\n",
    "import shutil\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "# Create new folder even if it already exists (overwrites existing)\n",
    "def refresh_dir(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "# Create folder only if it doesn't exist\n",
    "def make_dir(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "# Normalize all data columns to exactly 101 data points for time standardization\n",
    "def resample_ALL(datum):\n",
    "    newColumns = datum.columns\n",
    "    # Create new dataframe for time-normalized data\n",
    "    norm_datum = pd.DataFrame(columns=newColumns)\n",
    "    for i in range(0,len(datum.columns)): # Process all columns (IMU and force plate data)\n",
    "        raw_Data = datum.iloc[:,i]\n",
    "        norm_Data = signal.resample(raw_Data,101) # Resample to exactly 101 points using FFT-based method\n",
    "        norm_datum[datum.columns[i]] = norm_Data\n",
    "    return norm_datum\n",
    "    \n",
    "# Alternative resampling using polynomial interpolation for smoother results\n",
    "def resample_poly_ALL(datum):\n",
    "    newColumns = datum.columns\n",
    "    # Create new dataframe for time-normalized data\n",
    "    norm_datum = pd.DataFrame(columns=newColumns)\n",
    "    for i in range(0,len(datum.columns)): # Process all columns \n",
    "        raw_Data = datum.iloc[:,i]\n",
    "        norm_Data = signal.resample_poly(raw_Data,101,len(raw_Data),padtype='line') # Resample to 101 points using polyphase filtering\n",
    "        norm_datum[datum.columns[i]] = norm_Data\n",
    "    return norm_datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "dataDir =     r'R:\\KumarLab3\\PROJECTS\\wesens\\Data\\Analysis\\smith_dl\\IMU Deep Learning\\Data\\allnew_20220325_raw_byDeepak_csv\\INC_ByStep\\INC_ByZero\\Included_checked'\n",
    "rawDir =      os.path.join(dataDir, r'RAW')\n",
    "filteredDir = os.path.join(dataDir, r'FILT')\n",
    "nordDir =     os.path.join(dataDir,r'NORM')\n",
    "# Never create rawDir here\n",
    "# It must be created beforehand in the previous step\n",
    "make_dir(nordDir)\n",
    "dataExt = r\".csv\"\n",
    "# Get file list\n",
    "# Get entire file list, select only needed extensions, and exclude everything except CSV files from the retrieved file list\n",
    "dataList = natsorted([_ for _ in os.listdir(filteredDir) if _.endswith(dataExt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f51bacd217f475bb3d06c3e9d2a4eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file in tqdm(dataList):\n",
    "    datum = pd.read_csv(os.path.join(filteredDir, file))  # Load filtered data from FILT directory\n",
    "    # filt_datum = resample_ALL(datum)  # Basic FFT-based resampling (commented out)\n",
    "    filt_datum = resample_poly_ALL(datum) # Use polynomial resampling - seems to give better results?\n",
    "    namefornorm = \"N_\"+ file  # Add \"N_\" prefix to indicate normalized data\n",
    "    filt_datum.to_csv(os.path.join(nordDir,namefornorm),index=False)  # Save normalized data to NORM directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "vscode": {
   "interpreter": {
    "hash": "d11ad73ad699d301a1dd99211df442ecf876bf2f0364de9538efd8038a80f689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
