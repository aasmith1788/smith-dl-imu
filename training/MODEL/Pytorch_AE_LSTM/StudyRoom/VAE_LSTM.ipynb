{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설정\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "from pickle import load\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 설정 영역 ########\n",
    "# 실험 관련 세팅\n",
    "exp_name = 'torch_20220511' # 실험 이름 혹은 오늘 날짜\n",
    "modelVersion = 'Dense_1st_torch'\n",
    "nameDataset = 'IWALQQ_AE_1st'\n",
    "dataType = 'angle' # or moBWHT\n",
    "\n",
    "#################################\n",
    "# 여기는 grid로 돌림!\n",
    "#################################\n",
    "list_learningRate = {0:0.006, 1:0.008, 2:0.01} # opt1 \n",
    "list_batch_size = {0:128} # opt2\n",
    "list_lossFunction =  {0:\"MAE\"} # opt2\n",
    "\n",
    "totalFold = 5 # total fold, I did 5-fold cross validation\n",
    "epochs = 1000 # total epoch \n",
    "log_interval = 10 # frequency for saving log file\n",
    "count = 0 # In SCC, get count for grid-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 모델을 구현하기 위한 세부 sub module\n",
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim, device):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.seq_len, self.n_features = seq_len, n_features\n",
    "        self.embedding_dim, self.hidden_dim = (\n",
    "            embedding_dim, 2 * embedding_dim\n",
    "        )\n",
    "        self.rnn1 = nn.LSTM(\n",
    "          input_size=n_features,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          bidirectional=True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "          input_size=self.hidden_dim * 2,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          bidirectional=True\n",
    "        )\n",
    "        self.mu = torch.nn.Linear(self.embedding_dim * 2, self.embedding_dim) # bidirectianl이 켜져 있어서 그럼\n",
    "        self.sigma = torch.nn.Linear(self.embedding_dim * 2, self.embedding_dim) # bidirectianl이 켜져 있어서 그럼\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        # cuda()\n",
    "        if device == 'cuda':\n",
    "          self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "          self.N.scale = self.N.scale.cuda()\n",
    "        if device == 'cpu':\n",
    "          self.N.loc = self.N.loc.cpu() # hack to get sampling on the GPU\n",
    "          self.N.scale = self.N.scale.cpu()\n",
    "        self.kl = 0\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        mu =  self.mu(x[:,-1,:])\n",
    "        sigma = torch.exp(self.sigma(x[:,-1,:]))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return  z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "            LSTM-1       [32, 101, 42]          49,920          49,920\n",
      "            LSTM-2      [32, 101, 120]          36,480          36,480\n",
      "          Linear-3            [32, 60]           1,830           1,830\n",
      "          Linear-4            [32, 60]           1,830           1,830\n",
      "=======================================================================\n",
      "Total params: 90,060\n",
      "Trainable params: 90,060\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------\n",
      "      Layer (type)                                 Output Shape         Param #     Tr. Param #\n",
      "================================================================================================\n",
      "            LSTM-1     [32, 101, 120], [2, 32, 60], [2, 32, 60]          49,920          49,920\n",
      "            LSTM-2      [32, 101, 60], [2, 32, 30], [2, 32, 30]          36,480          36,480\n",
      "          Linear-3                                     [32, 30]           1,830           1,830\n",
      "          Linear-4                                     [32, 30]           1,830           1,830\n",
      "================================================================================================\n",
      "Total params: 90,060\n",
      "Trainable params: 90,060\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# show input shape\n",
    "print(summary(VariationalEncoder(101, 42, 30, device), torch.zeros((32, 101, 42)), show_input=True))\n",
    "# show output shape\n",
    "print(summary(VariationalEncoder(101, 42, 30, device), torch.zeros((32, 101, 42)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346/25\n",
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, n = x.size(0), x.size(1)\n",
    "        x_reshape = x.contiguous().view(t * n, -1)  # (samples * timesteps, input_size)\n",
    "        y = self.module(x_reshape)\n",
    "        # We have to reshape Y\n",
    "        y = y.contiguous().view(t, n, -1)  # (samples, timesteps, output_size)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim, n_features):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_len, self.input_dim = seq_len, input_dim\n",
    "        self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "        self.rnn1 = nn.LSTM(\n",
    "          input_size=input_dim,\n",
    "          hidden_size=input_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          bidirectional = True\n",
    "        )\n",
    "        self.rnn2 = nn.LSTM(\n",
    "          input_size=input_dim * 2,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=1,\n",
    "          batch_first=True,\n",
    "          bidirectional = True\n",
    "        )\n",
    "        self.output_layer = torch.nn.Linear(self.hidden_dim * 2, self.n_features)\n",
    "        self.timedist = TimeDistributed(self.output_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f'decoder first shape of x: {x.shape}')\n",
    "        x = x.reshape(-1,1,self.input_dim).repeat(1,self.seq_len,1)\n",
    "        # print(f'decoder after repeatvector shape of x: {x.shape}')       \n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        # print(f'decoder last shape of x: {self.timedist(x).shape}')\n",
    "        return self.timedist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "        Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "              LSTM-1        [1, 101, 30]          14,880          14,880\n",
      "              LSTM-2        [1, 101, 60]          58,560          58,560\n",
      "   TimeDistributed-3       [1, 101, 120]           5,082           5,082\n",
      "=========================================================================\n",
      "Total params: 78,522\n",
      "Trainable params: 78,522\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------------\n",
      "        Layer (type)                              Output Shape         Param #     Tr. Param #\n",
      "===============================================================================================\n",
      "              LSTM-1      [1, 101, 60], [2, 1, 30], [2, 1, 30]          14,880          14,880\n",
      "              LSTM-2     [1, 101, 120], [2, 1, 60], [2, 1, 60]          58,560          58,560\n",
      "   TimeDistributed-3                              [1, 101, 42]           5,082           5,082\n",
      "===============================================================================================\n",
      "Total params: 78,522\n",
      "Trainable params: 78,522\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# show input shape\n",
    "print(summary(Decoder(101, 30, 42), torch.zeros((30)), show_input=True))\n",
    "# show output shape\n",
    "print(summary(Decoder(101, 30, 42), torch.zeros((30)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main module\n",
    "class RecurrentVariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=30, device='cuda'):\n",
    "        super(RecurrentVariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(seq_len, n_features, embedding_dim, device).to(device)\n",
    "        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "    def forward(self, x):\n",
    "        # print(f'first shape of x: {x.shape}')\n",
    "        z = self.encoder(x)\n",
    "        # print(f'last shape of x: {x.shape}')\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "           Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "============================================================================\n",
      "   VariationalEncoder-1       [16, 101, 42]          90,060          90,060\n",
      "              Decoder-2            [16, 30]          78,522          78,522\n",
      "============================================================================\n",
      "Total params: 168,582\n",
      "Trainable params: 168,582\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "           Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "============================================================================\n",
      "   VariationalEncoder-1            [16, 30]          90,060          90,060\n",
      "              Decoder-2       [16, 101, 42]          78,522          78,522\n",
      "============================================================================\n",
      "Total params: 168,582\n",
      "Trainable params: 168,582\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# show input shape\n",
    "print(summary(RecurrentVariationalAutoencoder(101, 42, 30, device), torch.zeros((16, 101, 42)), show_input=True))\n",
    "\n",
    "# show output shape\n",
    "print(summary(RecurrentVariationalAutoencoder(101, 42, 30, device), torch.zeros((16, 101, 42)), show_input=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프 함수화 (구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습루프 구현하기\n",
    "# def train(dataloader, model, loss_fn, optimizer, device): \n",
    "\n",
    "def train_vae(model, dataloader, summarywriter, epoch, device, optimizer,):\n",
    "    model.train()\n",
    "    for _, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = ((data - output)**2).sum() + model.encoder.kl \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0) # 이것은 모든 배치의 크기가 일정하지 않을 수 있기 때문에 이렇게 수행함! train_loss는 total loss of batch가 됨\n",
    "    train_loss /= len(dataloader.sampler)\n",
    "    summarywriter.add_scalar('loss(MAE)', train_loss, epoch)\n",
    "    summarywriter.add_hparams(\n",
    "                    {\"sess\": \"train\", \"Type\": dataType, \"lr\": learningRate, \"bsize\": batch_size, \"DS\":nameDataset , 'lossFunc':lossFunction}, \n",
    "                    { \n",
    "                        \"loss\": train_loss,\n",
    "                    }, \n",
    "                ) \n",
    "\n",
    "def test_vae(model, dataloader, summarywriter, epoch, device):\n",
    "    model.eval()  # batch norm이나 dropout 등을 train mode 변환\n",
    "    with torch.no_grad():  # autograd engine, 즉 backpropagatin이나 gradient 계산 등을 꺼서 memory usage를 줄이고 속도를 높임\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = ((data - output)**2).sum() + model.encoder.kl \n",
    "            test_loss += loss.item() * data.size(0)\n",
    "        test_loss /= len(dataloader.sampler)\n",
    "        summarywriter.add_scalar('loss(MAE)', test_loss, epoch)\n",
    "        summarywriter.add_hparams(\n",
    "                        {\"sess\": \"train\", \"Type\": dataType, \"lr\": learningRate, \"bsize\": batch_size, \"DS\":nameDataset , 'lossFunc':lossFunction}, \n",
    "                        { \n",
    "                            \"loss\": test_loss,\n",
    "                        }, \n",
    "                    ) \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프 함수화 (vae 예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, data, epochs=20):\n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in data:\n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = autoencoder(x)\n",
    "            loss = ((x - x_hat)**2).sum() + autoencoder.encoder.kl\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프 함수화 (예제)\n",
    "- 참고 https://koreapy.tistory.com/739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, device): \n",
    "    size = len(dataloader.dataset) \n",
    "    for batch, (X, y) in enumerate(dataloader): \n",
    "        X, y = X.to(device), y.to(device) \n",
    "        # Compute prediction error \n",
    "        pred = model(X) \n",
    "        loss = loss_fn(pred, y) \n",
    "        # Backpropagation \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        if batch % 100 == 0: \n",
    "            loss, current = loss.item(), batch * len(X) \n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, device): \n",
    "    size = len(dataloader.dataset) \n",
    "    num_batches = len(dataloader) \n",
    "    model.eval() \n",
    "    test_loss, correct = 0, 0 \n",
    "    with torch.no_grad(): \n",
    "        for X, y in dataloader: X, y = X.to(device), y.to(device) \n",
    "        pred = model(X) \n",
    "        test_loss += loss_fn(pred, y).item() \n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item() \n",
    "        test_loss /= num_batches \n",
    "        correct /= size \n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5 \n",
    "for t in range(epochs): \n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn) \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배운것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3, 4)\n",
    "print(a.size())\n",
    "print(a.stride())\n",
    "print(a.is_contiguous())\n",
    "a = a.transpose(0, 1)\n",
    "print(a.is_contiguous())\n",
    "a = a.contiguous()\n",
    "a = a.view(-1)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mz:\\PROJECTS\\iwalqq\\Data\\V3D\\Output\\IMU Deep Learning\\IMUforKnee\\training\\MODEL\\Pytorch_AE_LSTM\\StudyRoom\\VAE_LSTM.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/z%3A/PROJECTS/iwalqq/Data/V3D/Output/IMU%20Deep%20Learning/IMUforKnee/training/MODEL/Pytorch_AE_LSTM/StudyRoom/VAE_LSTM.ipynb#ch0000021?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m ((data \u001b[39m-\u001b[39m output)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "a = ((data - output)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13b808b5077e789f7dde84b4147c1c98f2537031315824d3f8153389e6a3e631"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
