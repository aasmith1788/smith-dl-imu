{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"We create neural nets by subclassing the torch.nn.Module class in\n",
    "    the newly defined class, we define 2 things:\n",
    "    1) The network elements/layers; these are defined in the __init__ method\n",
    "    2) The network behavior! What happens when we call our model on an input\n",
    "    (here we call the input 'x')\n",
    "\n",
    "    Our model is thus composed of 2 Conv and 2 Linear layers, each with a\n",
    "    different size. When we call our model against an input example, we compute\n",
    "    the output from each layer and in between we apply the ReLU function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=5)\n",
    "        self.layer2 = torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=5)\n",
    "        self.layer3 = torch.nn.Linear(800, 16)\n",
    "        self.layer4 = torch.nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass through conv layers\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        # pass through linear layers\n",
    "        x = torch.flatten(x, start_dim=1)  # flatten the output of convolution\n",
    "        x = self.layer3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# we initialize our model as thus:\n",
    "# Congrats! You just built a neural network with PyTorch :-)\n",
    "my_model = Net()\n",
    "\n",
    "\n",
    "# GPU-aware programming\n",
    "\"\"\"\n",
    "our PyTorch module loads automatically to CPU, and afterwards we can decide to\n",
    "send it to GPU using .to() method. In fact tensor.to() method can send any\n",
    "PyTorch tensor to any device, not just models.\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9017f964ece69a1881201e9842c94c23e00b0e3c9573699033b2bdebcff634b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('sccIMU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
